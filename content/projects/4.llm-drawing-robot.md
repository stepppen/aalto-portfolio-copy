---
title: "LLM Drawing Robot"
slug: "llm-drawing-robot"
oneLiner: "An LLM & Generative AI powered drawing bot"
aspectRatio: "4:3"
preview: "TsunComp/thumb.webp"
role: |
  3D Modelling & Animation  
  UX/UI Design  
  Information Architecture
year: 2024
context: "Summer internship at Volkswagen HQ in Wolfsburg, Germany"
team: "Stepan Vedunov"
id: 4
---

::starter-grid{columns="cols-2"}
::hero-image{src="TsunComp/thumb.webp" alt="LLM Drawing Robot"}
::
::project-intro{:roles="Industrial Design, GUI" :team="David Polke, Elia Salerno, Andreas Kohler, Stepan Vedunov" title="LLM Drawing Robot" year="2023" context="University Module"}
In a three-week university module, we built a speech-to-drawing system that turns spoken requests into custom pen illustrations. The goal was to explore novel experiences using natural language and AI models: Using GPT-3.5, Stable Diffusion, and a custom-built plotter, it generates unique images drawn on paper for visitors to keep.
::
::

::divider{title="Video"}
::
::project-video{id="KK_POE7b3FM" alt="Video of LLM robot" caption="Video capturing the interaction with the robot."}
::

::divider{title="Process"}
::
::content-grid{columns="cols-2"}
::grid-image{src="/TsunComp/user_input.svg" alt="Initial Brainstorming" caption="Brainstorming possible input mechanisms"}
::
::grid-image{src="/TsunComp/pipeline.svg" alt="Tech Pipeline" caption="Tech pipeline of the entire process from human input to final drawing"}
::
::
::content-grid{columns="cols-2"}
::grid-image{src="/TsunComp/sketches.webp" alt="Sketches" caption="Sketching possible versions of the industrial design"}
::
::grid-image{src="/TsunComp/assembly.webp" alt="CAD assembly" caption="CAD assembly of the drawing robot"}
::
::
::content-grid{columns="cols-2"}
::text-container{title="Interaction"}
We aimed at creating a straightforward speech-input GUI inspired by social media voice messages to encourage natural, human-like interaction. This interface was central to our goal of exploring novel ways to engage with LLMs by replicating AI sentience through conversational exchanges.
::
::grid-image{src="/TsunComp/gui.gif" alt="Interactive GUI" caption="Video showing the speech input interaction"}
::
::

::divider{title="Results"}
::

::full-size-image{src="/TsunComp/render_01.webp" alt="3D Rendering" caption="Final 3D rendering of the robot"}
::

::content-grid{columns="cols-3"}
::grid-image{src="/TsunComp/render_04.webp" alt="Project Exhibition" caption="Project Exhibition"}
::
::grid-image{src="/TsunComp/render_02.webp" alt="User Interaction Photo" caption="User prompting the robot"}
::
::grid-image{src="/TsunComp/render_03.webp" alt="Robot drawing" caption="LLM drawing robot in action"}
::
::

::content-grid{columns="cols-2"}

::text-container{title="Learnings"}
The resulting prototype serves as a proof of concept for pseudo-sentience in AI. This foundation is core to the novel developments in HRI enabling more natural and meaningful interactions between humans and robots.
::
::
